{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Language Models Uncertainty Quantification (LUQ)","text":""},{"location":"#get-started","title":"Get Started","text":""},{"location":"#install-luq","title":"Install LUQ:","text":"<pre><code>pip install luq\n</code></pre>"},{"location":"#use-luq-model-for-uq","title":"Use LUQ model for UQ","text":"<pre><code>import luq\nfrom luq.models import MaxProbabilityEstimator\n\nmodel_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=\"auto\", device_map=\"auto\")\n# Create text generation pipeline\ngenerator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n\n# sample from LLM\nsamples = luq.llm.generate_n_samples_and_answer(\n    pipeline,\n    prompt=\"A, B, C, or D\"\n)\n\nmp_estimator = MaxProbabilityEstimator()\nprint(mp_estimator.estimate_uncertainty(samples))\n</code></pre>"},{"location":"#uncertainty-quantification-methods","title":"Uncertainty Quantification Methods","text":"<p>Generally the uncertainty quantification in LUQ sample multiple responses from an LLM and analyse the</p> Method Class in LUQ Note Reference Max Probability <code>luq.models.max_probability</code> Estimates uncertainty as one minus the probability of the most likely sequence in the list of samples. - Top K Gap <code>luq.models.top_k_gap</code> Estimates uncertainty by measuring the gap between the most probable sequence and the k-th most probable one. - Predictive Entropy <code>luq.models.predictive_entropy</code> Uncertainty is estimated by computing the entropy of probabilities obtained from sampled sequences. https://arxiv.org/pdf/2002.07650 p(true) <code>luq.models.p_true</code> Uncertainty is estimated by computing the entropy of probabilities obtained from sampled sequences. https://arxiv.org/pdf/2002.07650 Semantic Entropy <code>luq.models.semantic_entropy</code> Uncertainty is estimated by performing semantic clustering of LLM responses and calculating the entropy across the clusters. https://arxiv.org/abs/2302.09664 Kernel Language Entropy <code>luq.models.kernel_language_entropy</code> Uncertainty is estimated by performing semantic clustering of LLM responses and calculating the entropy across the clusters. https://arxiv.org/abs/2405.20003"},{"location":"#contributing","title":"Contributing","text":""},{"location":"#use-pre-commit","title":"Use pre-commit","text":"<pre><code>pip install pre-commit\npre-commit install\n</code></pre>"},{"location":"#pipeline-for-dataset-creation","title":"Pipeline for dataset creation","text":""},{"location":"#step-1-create-a-processed-version-of-a-dataset","title":"Step 1. Create a processed version of a dataset.","text":"<pre><code>mkdir data/coqa\npython scripts/process_datasets.py \\\n    --dataset=coqa \\\n    --output=data/coqa/processed.json\n</code></pre> <pre><code>import json\n\ndata = json.load(open(\"data/coqa/processed.json\", \"r\"))\nnew_data = {\"train\": data[\"train\"][:2], \"validation\": data[\"validation\"][:2]}\njson.dump(new_data, open(\"data/coqa/processed_short.json\", \"w\"))\n</code></pre>"},{"location":"#step-2-generate-answers-from-llms-and-augment-the-dataset-with-the-dataset","title":"Step 2. Generate answers from LLMs and augment the dataset with the dataset.","text":"<pre><code>python scripts/add_generations_to_dataset.py \\\n    --input-file=./data/coqa/processed_short.json\\\n    --output-file=./data/coqa/processed_gen_short.json\\\n</code></pre>"},{"location":"#step-3-check-accuracy-of-the-answers-given","title":"Step 3. Check accuracy of the answers given","text":"<pre><code>python scripts/eval_accuracy.py \\\n    --input-file=data/coqa/processed_gen_short.json \\\n    --output-file=data/coqa/processed_gen_acc_short.json \\\n    --model-name=gpt2 \\\n    --model-type=huggingface\n</code></pre>"},{"location":"#step-4-upload-the-dataset-to-huggingface","title":"Step 4. Upload the dataset to HuggingFace","text":"<pre><code>python scripts/upload_dataset.py \\\n    --path=data/coqa/processed_gen_acc_short.json \\\n    --repo-id your-username/dataset-name \\\n    --token your-huggingface-token\n</code></pre>"},{"location":"#datasets-end-to-end","title":"Datasets end-to-end","text":"<p>In order to generate a dataset: <pre><code>python scripts/gen_dataset.py --input-file=./data/dummy_data/raw_dummy.json --output-file=./output.json\n</code></pre></p> <p>When a dataset is created we can augment it with accuracies checked by another LLM: <pre><code>python scripts/eval_accuracy.py --input-file ./output.json --output-file test.json --model-name=gpt2 --model-type=huggingface\n</code></pre></p>"},{"location":"reference/","title":"LUQ API Documentation","text":""},{"location":"reference/#methods","title":"Methods","text":""},{"location":"reference/#luq.methods.BaseUQModel","title":"<code>BaseUQModel</code>","text":"Source code in <code>luq/methods/base_uq_model.py</code> <pre><code>class BaseUQModel:\n    def compute_sequence_probability(\n        self, logprobs: torch.Tensor, seq_prob_mode: SeqProbMode = SeqProbMode.PROD\n    ) -&gt; float:\n        \"\"\"\n        Computes the probability of a response sequence.\n        \"\"\"\n        token_probs = torch.exp(logprobs)  # Convert logits to probabilities\n        if seq_prob_mode == SeqProbMode.PROD:\n            return torch.prod(token_probs).item()\n        elif seq_prob_mode == SeqProbMode.AVG:\n            return torch.mean(token_probs).item()\n        else:\n            raise ValueError(f\"Unknown seq_prob_mode: {seq_prob_mode}\")\n\n    def normalize_sequence_probs(\n        self, probs: List[float], tolerance: float = 1e-9\n    ) -&gt; float:\n        z = sum(probs)\n        if abs(z) &lt; tolerance:\n            return [1.0 / len(probs)] * len(probs)\n        return [p / z for p in probs]\n\n    def estimate_uncertainty(self, prompt: str, *args, **kwargs) -&gt; float:\n        raise NotImplementedError(\"method get_uncertainty is not implemented\")\n</code></pre>"},{"location":"reference/#luq.methods.BaseUQModel.compute_sequence_probability","title":"<code>compute_sequence_probability(logprobs, seq_prob_mode=SeqProbMode.PROD)</code>","text":"<p>Computes the probability of a response sequence.</p> Source code in <code>luq/methods/base_uq_model.py</code> <pre><code>def compute_sequence_probability(\n    self, logprobs: torch.Tensor, seq_prob_mode: SeqProbMode = SeqProbMode.PROD\n) -&gt; float:\n    \"\"\"\n    Computes the probability of a response sequence.\n    \"\"\"\n    token_probs = torch.exp(logprobs)  # Convert logits to probabilities\n    if seq_prob_mode == SeqProbMode.PROD:\n        return torch.prod(token_probs).item()\n    elif seq_prob_mode == SeqProbMode.AVG:\n        return torch.mean(token_probs).item()\n    else:\n        raise ValueError(f\"Unknown seq_prob_mode: {seq_prob_mode}\")\n</code></pre>"},{"location":"reference/#luq.methods.KernelLanguageEntropyEstimator","title":"<code>KernelLanguageEntropyEstimator</code>","text":"<p>               Bases: <code>BaseUQModel</code></p> Source code in <code>luq/methods/kernel_language_entropy.py</code> <pre><code>class KernelLanguageEntropyEstimator(BaseUQModel):\n    def __init__(self):\n        super().__init__()\n\n    def compute_entropy(\n        self,\n        kernel: torch.Tensor,\n        normalize: bool = False,\n    ) -&gt; float:\n        if normalize:\n            kernel = normalize_kernel(kernel)\n        return von_neumann_entropy(kernel)\n\n    def get_kernel(\n        self,\n        samples: LLMSamples,\n        kernel_type: KernelType | None = None,\n        construct_kernel: T.Callable | None = None,\n        nli_model: NLIWrapper | None = None,\n        nli_table: NLITable | None = None,\n    ) -&gt; torch.Tensor:\n        if kernel_type is not None and construct_kernel is not None:\n            raise ValueError(\n                \"Only one of `kernel_type` and `construct_kernel` should be specified\"\n            )\n        if kernel_type is None and construct_kernel is None:\n            raise ValueError(\n                \"Either `kernel_type` or `construct_kernel` should be specified\"\n            )\n\n        if kernel_type is not None:\n            kernel = None\n            if kernel_type == KernelType.HEAT:\n                # todo: calculate heat kernel\n                pass\n            elif kernel_type == KernelType.MATERN:\n                # todo: calculate Matern kernel\n                pass\n            else:\n                raise ValueError(f\"Unknown kernel type: {kernel_type}\")\n        else:\n            kernel = construct_kernel(samples)\n        kernel = normalize_kernel(kernel)\n        return kernel\n\n    def estimate_uncertainty(\n        self,\n        samples: LLMSamples,\n        seq_prob_mode: SeqProbMode = SeqProbMode.PROD,\n        kernel_type: KernelType = KernelType.HEAT,\n        nli_model: NLIWrapper | None = None,\n        nli_table: NLITable | None = None,\n        construct_kernel: T.Callable | None = None,\n        **kwargs,\n    ) -&gt; float:\n        \"\"\"\n        Estimates uncertainty by constructing a semantic similarity matrix and computing its von Neumann entropy.\n        \"\"\"\n        # validation\n        if nli_model is None and nli_table is None:\n            raise ValueError(\"Either `nli_model` or `nli_table` should be provided\")\n\n        if nli_model is not None and nli_table is not None:\n            raise ValueError(\n                \"Only one of `nli_model` and `nli_table` should be provided\"\n            )\n\n        kernel = self.get_kernel(\n            samples,\n            kernel_type=kernel_type,\n            construct_kernel=construct_kernel,\n            nli_model=nli_model,\n            nli_table=nli_table,\n        )\n        # Compute entropy over clusters\n        return self.compute_entropy(kernel)\n</code></pre>"},{"location":"reference/#luq.methods.KernelLanguageEntropyEstimator.estimate_uncertainty","title":"<code>estimate_uncertainty(samples, seq_prob_mode=SeqProbMode.PROD, kernel_type=KernelType.HEAT, nli_model=None, nli_table=None, construct_kernel=None, **kwargs)</code>","text":"<p>Estimates uncertainty by constructing a semantic similarity matrix and computing its von Neumann entropy.</p> Source code in <code>luq/methods/kernel_language_entropy.py</code> <pre><code>def estimate_uncertainty(\n    self,\n    samples: LLMSamples,\n    seq_prob_mode: SeqProbMode = SeqProbMode.PROD,\n    kernel_type: KernelType = KernelType.HEAT,\n    nli_model: NLIWrapper | None = None,\n    nli_table: NLITable | None = None,\n    construct_kernel: T.Callable | None = None,\n    **kwargs,\n) -&gt; float:\n    \"\"\"\n    Estimates uncertainty by constructing a semantic similarity matrix and computing its von Neumann entropy.\n    \"\"\"\n    # validation\n    if nli_model is None and nli_table is None:\n        raise ValueError(\"Either `nli_model` or `nli_table` should be provided\")\n\n    if nli_model is not None and nli_table is not None:\n        raise ValueError(\n            \"Only one of `nli_model` and `nli_table` should be provided\"\n        )\n\n    kernel = self.get_kernel(\n        samples,\n        kernel_type=kernel_type,\n        construct_kernel=construct_kernel,\n        nli_model=nli_model,\n        nli_table=nli_table,\n    )\n    # Compute entropy over clusters\n    return self.compute_entropy(kernel)\n</code></pre>"},{"location":"reference/#luq.methods.LLMWrapper","title":"<code>LLMWrapper</code>","text":"Source code in <code>luq/models/llm.py</code> <pre><code>class LLMWrapper:\n    def __call__(self, *args, **kwargs) -&gt; LLMOutput:\n        \"\"\"\n        Return a response of an LLM\n        \"\"\"\n        raise NotImplementedError(\"__call__ should be implemented for your LLM\")\n</code></pre>"},{"location":"reference/#luq.methods.LLMWrapper.__call__","title":"<code>__call__(*args, **kwargs)</code>","text":"<p>Return a response of an LLM</p> Source code in <code>luq/models/llm.py</code> <pre><code>def __call__(self, *args, **kwargs) -&gt; LLMOutput:\n    \"\"\"\n    Return a response of an LLM\n    \"\"\"\n    raise NotImplementedError(\"__call__ should be implemented for your LLM\")\n</code></pre>"},{"location":"reference/#luq.methods.MaxProbabilityEstimator","title":"<code>MaxProbabilityEstimator</code>","text":"<p>               Bases: <code>BaseUQModel</code></p> Source code in <code>luq/methods/max_probability.py</code> <pre><code>class MaxProbabilityEstimator(BaseUQModel):\n    def estimate_uncertainty(\n        self,\n        samples: T.List[LLMOutput],\n        seq_prob_mode: SeqProbMode = SeqProbMode.PROD,\n        **kwargs,\n    ) -&gt; float:\n        \"\"\"\n        Estimates uncertainty as one minus the probability of the most likely sequence in the list of samples.\n\n        :param prompt: The input prompt for LLM.\n        :param seq_prob_mode: Describes how token probabilities are translated into sequence probabilities\n        :return: entropy score\n        \"\"\"\n        assert all(s.logprobs is not None for s in samples.samples)\n\n        logit_samples = [s.logprobs for s in samples.samples]\n        sequence_probs = [\n            self.compute_sequence_probability(logits, seq_prob_mode)\n            for logits in logit_samples\n        ]\n        sequence_probs = self.normalize_sequence_probs(sequence_probs)\n        return 1 - max(sequence_probs)\n</code></pre>"},{"location":"reference/#luq.methods.MaxProbabilityEstimator.estimate_uncertainty","title":"<code>estimate_uncertainty(samples, seq_prob_mode=SeqProbMode.PROD, **kwargs)</code>","text":"<p>Estimates uncertainty as one minus the probability of the most likely sequence in the list of samples.</p> <p>:param prompt: The input prompt for LLM. :param seq_prob_mode: Describes how token probabilities are translated into sequence probabilities :return: entropy score</p> Source code in <code>luq/methods/max_probability.py</code> <pre><code>def estimate_uncertainty(\n    self,\n    samples: T.List[LLMOutput],\n    seq_prob_mode: SeqProbMode = SeqProbMode.PROD,\n    **kwargs,\n) -&gt; float:\n    \"\"\"\n    Estimates uncertainty as one minus the probability of the most likely sequence in the list of samples.\n\n    :param prompt: The input prompt for LLM.\n    :param seq_prob_mode: Describes how token probabilities are translated into sequence probabilities\n    :return: entropy score\n    \"\"\"\n    assert all(s.logprobs is not None for s in samples.samples)\n\n    logit_samples = [s.logprobs for s in samples.samples]\n    sequence_probs = [\n        self.compute_sequence_probability(logits, seq_prob_mode)\n        for logits in logit_samples\n    ]\n    sequence_probs = self.normalize_sequence_probs(sequence_probs)\n    return 1 - max(sequence_probs)\n</code></pre>"},{"location":"reference/#luq.methods.PredictiveEntropyEstimator","title":"<code>PredictiveEntropyEstimator</code>","text":"<p>               Bases: <code>BaseUQModel</code></p> Source code in <code>luq/methods/predictive_entropy.py</code> <pre><code>class PredictiveEntropyEstimator(BaseUQModel):\n    def generate_logits(self, prompt: str, num_samples: int = 10) -&gt; T.List:\n        \"\"\"\n        Generates multiple responses and extracts their logits.\n\n        :param prompt: The input prompt for the LLM.\n        :return: List of logit sequences.\n        \"\"\"\n        logit_samples = []\n\n        for _ in range(num_samples):\n            if isinstance(self._llm, LLMWrapper):\n                response = self._llm(prompt)\n            else:\n                raise ValueError(\n                    f\"Cannot compute logits LogitUncertaintyQuantification for {type(self._llm)}\"\n                )\n            logit_samples.append(response.logits)\n\n        return logit_samples\n\n    def compute_entropy(self, sequence_probs):\n        \"\"\"\n        Computes entropy over the sampled sequence probabilities.\n\n        :param sequence_probs: List of sequence probabilities.\n        :return: Entropy value.\n        \"\"\"\n        if not isinstance(sequence_probs, torch.Tensor):\n            sequence_probs = torch.tensor(sequence_probs)\n\n        sequence_probs /= sum(\n            sequence_probs\n        )  # Normalize to form a probability distribution\n        return entropy(sequence_probs)\n\n    def estimate_uncertainty(\n        self,\n        samples: T.List[LLMOutput],\n        seq_prob_mode: SeqProbMode = SeqProbMode.PROD,\n        **kwargs,\n    ) -&gt; float:\n        \"\"\"\n        Uncertainty is estimated by computing the entropy of probabilities obtained from sampled sequences.\n\n        :param prompt: The input prompt for LLM.\n        :param seq_prob_mode: Describes how token probabilities are translated into sequence probabilities\n        :return: entropy score\n        \"\"\"\n        assert all(s.logprobs is not None for s in samples.samples)\n\n        logit_samples = [s.logprobs for s in samples.samples]\n        sequence_probs = [\n            self.compute_sequence_probability(logits, seq_prob_mode)\n            for logits in logit_samples\n        ]\n        entropy_value = self.compute_entropy(sequence_probs)\n\n        return entropy_value\n</code></pre>"},{"location":"reference/#luq.methods.PredictiveEntropyEstimator.compute_entropy","title":"<code>compute_entropy(sequence_probs)</code>","text":"<p>Computes entropy over the sampled sequence probabilities.</p> <p>:param sequence_probs: List of sequence probabilities. :return: Entropy value.</p> Source code in <code>luq/methods/predictive_entropy.py</code> <pre><code>def compute_entropy(self, sequence_probs):\n    \"\"\"\n    Computes entropy over the sampled sequence probabilities.\n\n    :param sequence_probs: List of sequence probabilities.\n    :return: Entropy value.\n    \"\"\"\n    if not isinstance(sequence_probs, torch.Tensor):\n        sequence_probs = torch.tensor(sequence_probs)\n\n    sequence_probs /= sum(\n        sequence_probs\n    )  # Normalize to form a probability distribution\n    return entropy(sequence_probs)\n</code></pre>"},{"location":"reference/#luq.methods.PredictiveEntropyEstimator.estimate_uncertainty","title":"<code>estimate_uncertainty(samples, seq_prob_mode=SeqProbMode.PROD, **kwargs)</code>","text":"<p>Uncertainty is estimated by computing the entropy of probabilities obtained from sampled sequences.</p> <p>:param prompt: The input prompt for LLM. :param seq_prob_mode: Describes how token probabilities are translated into sequence probabilities :return: entropy score</p> Source code in <code>luq/methods/predictive_entropy.py</code> <pre><code>def estimate_uncertainty(\n    self,\n    samples: T.List[LLMOutput],\n    seq_prob_mode: SeqProbMode = SeqProbMode.PROD,\n    **kwargs,\n) -&gt; float:\n    \"\"\"\n    Uncertainty is estimated by computing the entropy of probabilities obtained from sampled sequences.\n\n    :param prompt: The input prompt for LLM.\n    :param seq_prob_mode: Describes how token probabilities are translated into sequence probabilities\n    :return: entropy score\n    \"\"\"\n    assert all(s.logprobs is not None for s in samples.samples)\n\n    logit_samples = [s.logprobs for s in samples.samples]\n    sequence_probs = [\n        self.compute_sequence_probability(logits, seq_prob_mode)\n        for logits in logit_samples\n    ]\n    entropy_value = self.compute_entropy(sequence_probs)\n\n    return entropy_value\n</code></pre>"},{"location":"reference/#luq.methods.PredictiveEntropyEstimator.generate_logits","title":"<code>generate_logits(prompt, num_samples=10)</code>","text":"<p>Generates multiple responses and extracts their logits.</p> <p>:param prompt: The input prompt for the LLM. :return: List of logit sequences.</p> Source code in <code>luq/methods/predictive_entropy.py</code> <pre><code>def generate_logits(self, prompt: str, num_samples: int = 10) -&gt; T.List:\n    \"\"\"\n    Generates multiple responses and extracts their logits.\n\n    :param prompt: The input prompt for the LLM.\n    :return: List of logit sequences.\n    \"\"\"\n    logit_samples = []\n\n    for _ in range(num_samples):\n        if isinstance(self._llm, LLMWrapper):\n            response = self._llm(prompt)\n        else:\n            raise ValueError(\n                f\"Cannot compute logits LogitUncertaintyQuantification for {type(self._llm)}\"\n            )\n        logit_samples.append(response.logits)\n\n    return logit_samples\n</code></pre>"},{"location":"reference/#luq.methods.SemanticEntropyEstimator","title":"<code>SemanticEntropyEstimator</code>","text":"<p>               Bases: <code>BaseUQModel</code></p> Source code in <code>luq/methods/semantic_entropy.py</code> <pre><code>class SemanticEntropyEstimator(BaseUQModel):\n    def __init__(self):\n        super().__init__()\n\n    def compute_entropy(\n        self, cluster_assignments: T.List[int], sequence_probs: T.List[float] | None\n    ) -&gt; float:\n        \"\"\"\n        Computes entropy over clusters using sequence probabilities or cluster sizes.\n        \"\"\"\n        if sequence_probs is None:\n            # Discrete Semantic Entropy\n            cluster_counts = Counter(cluster_assignments)\n            cluster_probs = torch.tensor(\n                [\n                    count / sum(cluster_counts.values())\n                    for count in cluster_counts.values()\n                ]\n            )\n        else:\n            # Continuous Semantic Entropy with sequence probabilities\n            cluster_probs = torch.zeros(max(cluster_assignments) + 1)\n            for cluster_id, prob in zip(cluster_assignments, sequence_probs):\n                cluster_probs[cluster_id] += prob\n            # Normalize probabilities\n            cluster_probs = cluster_probs / torch.sum(cluster_probs)\n\n        return entropy(cluster_probs)\n\n    def estimate_uncertainty(\n        self,\n        samples: LLMSamples,\n        seq_prob_mode: SeqProbMode = SeqProbMode.PROD,\n        nli_model: NLIWrapper | None = None,\n        nli_table: NLITable | None = None,\n        **kwargs,\n    ) -&gt; float:\n        \"\"\"\n        Uncertainty is estimated by performing semantic clustering of LLM responses and calculating the entropy across the clusters.\n        \"\"\"\n\n        # validation\n        if nli_model is None and nli_table is None:\n            raise ValueError(\"Either `nli_model` or `nli_table` should be provided\")\n\n        if nli_model is not None and nli_table is not None:\n            raise ValueError(\n                \"Only one of `nli_model` and `nli_table` should be provided\"\n            )\n\n        logit_samples = [s.logprobs for s in samples.samples]\n\n        # Compute sequence probabilities\n        sequence_probs = [\n            self.compute_sequence_probability(logits, seq_prob_mode)\n            for logits in logit_samples\n        ]\n\n        if nli_table is None:\n            nli_table = construct_nli_table(samples, nli_model)\n\n        # Cluster responses\n        cluster_assignments = hard_nli_clustering(samples, nli_table)\n\n        # Compute entropy over clusters\n        return self.compute_entropy(cluster_assignments, sequence_probs)\n</code></pre>"},{"location":"reference/#luq.methods.SemanticEntropyEstimator.compute_entropy","title":"<code>compute_entropy(cluster_assignments, sequence_probs)</code>","text":"<p>Computes entropy over clusters using sequence probabilities or cluster sizes.</p> Source code in <code>luq/methods/semantic_entropy.py</code> <pre><code>def compute_entropy(\n    self, cluster_assignments: T.List[int], sequence_probs: T.List[float] | None\n) -&gt; float:\n    \"\"\"\n    Computes entropy over clusters using sequence probabilities or cluster sizes.\n    \"\"\"\n    if sequence_probs is None:\n        # Discrete Semantic Entropy\n        cluster_counts = Counter(cluster_assignments)\n        cluster_probs = torch.tensor(\n            [\n                count / sum(cluster_counts.values())\n                for count in cluster_counts.values()\n            ]\n        )\n    else:\n        # Continuous Semantic Entropy with sequence probabilities\n        cluster_probs = torch.zeros(max(cluster_assignments) + 1)\n        for cluster_id, prob in zip(cluster_assignments, sequence_probs):\n            cluster_probs[cluster_id] += prob\n        # Normalize probabilities\n        cluster_probs = cluster_probs / torch.sum(cluster_probs)\n\n    return entropy(cluster_probs)\n</code></pre>"},{"location":"reference/#luq.methods.SemanticEntropyEstimator.estimate_uncertainty","title":"<code>estimate_uncertainty(samples, seq_prob_mode=SeqProbMode.PROD, nli_model=None, nli_table=None, **kwargs)</code>","text":"<p>Uncertainty is estimated by performing semantic clustering of LLM responses and calculating the entropy across the clusters.</p> Source code in <code>luq/methods/semantic_entropy.py</code> <pre><code>def estimate_uncertainty(\n    self,\n    samples: LLMSamples,\n    seq_prob_mode: SeqProbMode = SeqProbMode.PROD,\n    nli_model: NLIWrapper | None = None,\n    nli_table: NLITable | None = None,\n    **kwargs,\n) -&gt; float:\n    \"\"\"\n    Uncertainty is estimated by performing semantic clustering of LLM responses and calculating the entropy across the clusters.\n    \"\"\"\n\n    # validation\n    if nli_model is None and nli_table is None:\n        raise ValueError(\"Either `nli_model` or `nli_table` should be provided\")\n\n    if nli_model is not None and nli_table is not None:\n        raise ValueError(\n            \"Only one of `nli_model` and `nli_table` should be provided\"\n        )\n\n    logit_samples = [s.logprobs for s in samples.samples]\n\n    # Compute sequence probabilities\n    sequence_probs = [\n        self.compute_sequence_probability(logits, seq_prob_mode)\n        for logits in logit_samples\n    ]\n\n    if nli_table is None:\n        nli_table = construct_nli_table(samples, nli_model)\n\n    # Cluster responses\n    cluster_assignments = hard_nli_clustering(samples, nli_table)\n\n    # Compute entropy over clusters\n    return self.compute_entropy(cluster_assignments, sequence_probs)\n</code></pre>"},{"location":"reference/#luq.methods.TopKGapEstimator","title":"<code>TopKGapEstimator</code>","text":"<p>               Bases: <code>BaseUQModel</code></p> Source code in <code>luq/methods/top_k_gap.py</code> <pre><code>class TopKGapEstimator(BaseUQModel):\n    def estimate_uncertainty(\n        self,\n        samples: T.List[LLMOutput],\n        seq_prob_mode: SeqProbMode = SeqProbMode.PROD,\n        k: int = 2,\n        **kwargs,\n    ) -&gt; float:\n        \"\"\"\n        Estimates uncertainty by computing entropy over sampled sequence probabilities.\n\n        :param prompt: The input prompt for LLM.\n        :param seq_prob_mode: Describes how token probabilities are translated into sequence probabilities\n        :return: entropy score\n        \"\"\"\n        if k &lt; 2:\n            raise ValueError(\"k should &gt;= 2\")\n        assert all(s.logprobs is not None for s in samples.samples)\n\n        logit_samples = [s.logprobs for s in samples.samples]\n        sequence_probs = [\n            self.compute_sequence_probability(logits, seq_prob_mode)\n            for logits in logit_samples\n        ]\n        sorted_seq_probs = sorted(sequence_probs)\n        gap = sorted_seq_probs[-1] - sorted_seq_probs[-k]\n        return 1 - gap\n</code></pre>"},{"location":"reference/#luq.methods.TopKGapEstimator.estimate_uncertainty","title":"<code>estimate_uncertainty(samples, seq_prob_mode=SeqProbMode.PROD, k=2, **kwargs)</code>","text":"<p>Estimates uncertainty by computing entropy over sampled sequence probabilities.</p> <p>:param prompt: The input prompt for LLM. :param seq_prob_mode: Describes how token probabilities are translated into sequence probabilities :return: entropy score</p> Source code in <code>luq/methods/top_k_gap.py</code> <pre><code>def estimate_uncertainty(\n    self,\n    samples: T.List[LLMOutput],\n    seq_prob_mode: SeqProbMode = SeqProbMode.PROD,\n    k: int = 2,\n    **kwargs,\n) -&gt; float:\n    \"\"\"\n    Estimates uncertainty by computing entropy over sampled sequence probabilities.\n\n    :param prompt: The input prompt for LLM.\n    :param seq_prob_mode: Describes how token probabilities are translated into sequence probabilities\n    :return: entropy score\n    \"\"\"\n    if k &lt; 2:\n        raise ValueError(\"k should &gt;= 2\")\n    assert all(s.logprobs is not None for s in samples.samples)\n\n    logit_samples = [s.logprobs for s in samples.samples]\n    sequence_probs = [\n        self.compute_sequence_probability(logits, seq_prob_mode)\n        for logits in logit_samples\n    ]\n    sorted_seq_probs = sorted(sequence_probs)\n    gap = sorted_seq_probs[-1] - sorted_seq_probs[-k]\n    return 1 - gap\n</code></pre>"},{"location":"reference/#luq.methods.entropy","title":"<code>entropy(probabilities)</code>","text":"<p>Compute entropy for a sequence of probabilities.</p> Source code in <code>luq/utils/utils.py</code> <pre><code>def entropy(probabilities: Union[List[float], torch.Tensor]) -&gt; torch.Tensor:\n    \"\"\"Compute entropy for a sequence of probabilities.\"\"\"\n    probabilities = (\n        torch.tensor(probabilities, dtype=torch.float32)\n        if isinstance(probabilities, list)\n        else probabilities\n    )\n    entropy_value = -torch.sum(probabilities * torch.log(probabilities + 1e-9))\n    return entropy_value.item()\n</code></pre>"},{"location":"reference/#models","title":"Models","text":""},{"location":"reference/#luq.models.BatchLLMWrapper","title":"<code>BatchLLMWrapper</code>","text":"Source code in <code>luq/models/llm.py</code> <pre><code>class BatchLLMWrapper:\n    def __call__(self, *args, **kwargs) -&gt; T.List[LLMOutput]:\n        \"\"\"\n        Return a response of an LLM\n        \"\"\"\n        raise NotImplementedError(\"__call__ should be implemented for your LLM\")\n</code></pre>"},{"location":"reference/#luq.models.BatchLLMWrapper.__call__","title":"<code>__call__(*args, **kwargs)</code>","text":"<p>Return a response of an LLM</p> Source code in <code>luq/models/llm.py</code> <pre><code>def __call__(self, *args, **kwargs) -&gt; T.List[LLMOutput]:\n    \"\"\"\n    Return a response of an LLM\n    \"\"\"\n    raise NotImplementedError(\"__call__ should be implemented for your LLM\")\n</code></pre>"},{"location":"reference/#luq.models.HFLLMWrapper","title":"<code>HFLLMWrapper</code>","text":"<p>               Bases: <code>LLMWrapper</code></p> Source code in <code>luq/models/llm.py</code> <pre><code>class HFLLMWrapper(LLMWrapper):\n    def __init__(\n        self, tokenizer: transformers.AutoTokenizer, model: transformers.PreTrainedModel\n    ):\n        if isinstance(tokenizer, transformers.PreTrainedTokenizerBase):\n            self.tokenizer = tokenizer\n        else:\n            raise ValueError(\"Requires a text generation pipeline from transformers\")\n        if isinstance(model, transformers.PreTrainedModel):\n            self.model = model\n        else:\n            raise ValueError(\"Requires a text generation pipeline from transformers\")\n\n    def __call__(\n        self,\n        prompt: str,\n        temperature: float = 1.0,\n        max_new_tokens=1024,\n        *args,\n        **kwargs\n    ) -&gt; LLMOutput:\n        \"\"\"\n        Return a response of an LLM\n        \"\"\"\n        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device)\n\n        with torch.no_grad():\n            outputs = self.model.generate(\n                **inputs,\n                max_new_tokens=50,\n                return_dict_in_generate=True,\n                output_scores=True,\n                do_sample=True,\n                temperature=1.0,\n            )\n        generated_ids = outputs.sequences[0]\n        generated_text = self.tokenizer.decode(generated_ids, skip_special_tokens=True)\n        token_scores = outputs.scores\n        generated_tokens = generated_ids[len(inputs[\"input_ids\"][0]) :]\n\n        logprobs = []\n        for i, token_id in enumerate(generated_tokens):\n            logits = token_scores[i][0]\n            log_probs = torch.nn.functional.log_softmax(logits, dim=-1)\n            token_logprob = log_probs[token_id].item()\n            logprobs.append((self.tokenizer.decode([token_id]), token_logprob))\n\n        # logprobs is a list of pairs (token, logprob)\n        logprobs = [el[1] for el in logprobs]\n        return LLMOutput(\n            answer=generated_text,\n            logprobs=torch.tensor(logprobs, device=self.model.device),\n        )\n</code></pre>"},{"location":"reference/#luq.models.HFLLMWrapper.__call__","title":"<code>__call__(prompt, temperature=1.0, max_new_tokens=1024, *args, **kwargs)</code>","text":"<p>Return a response of an LLM</p> Source code in <code>luq/models/llm.py</code> <pre><code>def __call__(\n    self,\n    prompt: str,\n    temperature: float = 1.0,\n    max_new_tokens=1024,\n    *args,\n    **kwargs\n) -&gt; LLMOutput:\n    \"\"\"\n    Return a response of an LLM\n    \"\"\"\n    inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device)\n\n    with torch.no_grad():\n        outputs = self.model.generate(\n            **inputs,\n            max_new_tokens=50,\n            return_dict_in_generate=True,\n            output_scores=True,\n            do_sample=True,\n            temperature=1.0,\n        )\n    generated_ids = outputs.sequences[0]\n    generated_text = self.tokenizer.decode(generated_ids, skip_special_tokens=True)\n    token_scores = outputs.scores\n    generated_tokens = generated_ids[len(inputs[\"input_ids\"][0]) :]\n\n    logprobs = []\n    for i, token_id in enumerate(generated_tokens):\n        logits = token_scores[i][0]\n        log_probs = torch.nn.functional.log_softmax(logits, dim=-1)\n        token_logprob = log_probs[token_id].item()\n        logprobs.append((self.tokenizer.decode([token_id]), token_logprob))\n\n    # logprobs is a list of pairs (token, logprob)\n    logprobs = [el[1] for el in logprobs]\n    return LLMOutput(\n        answer=generated_text,\n        logprobs=torch.tensor(logprobs, device=self.model.device),\n    )\n</code></pre>"},{"location":"reference/#luq.models.LLMWrapper","title":"<code>LLMWrapper</code>","text":"Source code in <code>luq/models/llm.py</code> <pre><code>class LLMWrapper:\n    def __call__(self, *args, **kwargs) -&gt; LLMOutput:\n        \"\"\"\n        Return a response of an LLM\n        \"\"\"\n        raise NotImplementedError(\"__call__ should be implemented for your LLM\")\n</code></pre>"},{"location":"reference/#luq.models.LLMWrapper.__call__","title":"<code>__call__(*args, **kwargs)</code>","text":"<p>Return a response of an LLM</p> Source code in <code>luq/models/llm.py</code> <pre><code>def __call__(self, *args, **kwargs) -&gt; LLMOutput:\n    \"\"\"\n    Return a response of an LLM\n    \"\"\"\n    raise NotImplementedError(\"__call__ should be implemented for your LLM\")\n</code></pre>"},{"location":"reference/#datasets","title":"Datasets","text":""},{"location":"reference/#luq.datasets.GenerationDataset","title":"<code>GenerationDataset</code>","text":"<p>               Bases: <code>DatasetDict</code></p> Source code in <code>luq/datasets/dataset.py</code> <pre><code>class GenerationDataset(DatasetDict):\n    def __init__(self, data_path: str = None, arrow_table=None):\n        \"\"\"\n        Initializes the dataset object.\n        :param data_path: Path to the JSON file containing the dataset.\n        \"\"\"\n        if data_path is not None:\n            dataset_dict = self.load_from_json(data_path)\n            super().__init__(dataset_dict)\n        elif arrow_table is not None:\n            dataset = Dataset(arrow_table)\n            super().__init__({\"train\": dataset})\n        else:\n            raise ValueError(\"Either data_path or arrow_table must be provided\")\n\n    @staticmethod\n    def load_from_json(data_path: str) -&gt; Dataset:\n        \"\"\"\n        Loads the dataset from a JSON file and converts it into a Hugging Face Dataset object.\n        \"\"\"\n        with open(data_path, \"r\", encoding=\"utf-8\") as f:\n            raw_data = json.load(f)\n\n        split_datasets = {}\n        for split, items in raw_data[\"data\"].items():\n            processed_items = [\n                {\n                    \"question\": item[\"question\"],\n                    \"samples\": item[\"samples\"],\n                    \"logprobs\": item.get(\"logprobs\", []),\n                    \"answer\": item[\"answer\"],\n                    \"gt_answer\": item[\"gt_answer\"],\n                    \"accuracy\": item.get(\"accuracy\"),\n                }\n                for item in items\n            ]\n            split_datasets[split] = Dataset.from_list(processed_items)\n        return DatasetDict(split_datasets)\n\n    def split_dataset(self, train_size: float = 0.8) -&gt; Dict[str, \"GenerationDataset\"]:\n        \"\"\"\n        Splits the dataset into train and test sets.\n        :param train_size: Proportion of the dataset to include in the train split.\n        :return: Dictionary containing train and test GenerationDataset objects\n        \"\"\"\n        splits = super().train_test_split(train_size=train_size)\n        return {\n            \"train\": GenerationDataset(arrow_table=splits[\"train\"]._data),\n            \"test\": GenerationDataset(arrow_table=splits[\"test\"]._data),\n        }\n\n    @classmethod\n    def from_dataset(cls, dataset: Dataset) -&gt; \"GenerationDataset\":\n        \"\"\"\n        Creates a GenerationDataset from a regular Dataset object\n        \"\"\"\n        return cls(arrow_table=dataset._data)\n</code></pre>"},{"location":"reference/#luq.datasets.GenerationDataset.__init__","title":"<code>__init__(data_path=None, arrow_table=None)</code>","text":"<p>Initializes the dataset object. :param data_path: Path to the JSON file containing the dataset.</p> Source code in <code>luq/datasets/dataset.py</code> <pre><code>def __init__(self, data_path: str = None, arrow_table=None):\n    \"\"\"\n    Initializes the dataset object.\n    :param data_path: Path to the JSON file containing the dataset.\n    \"\"\"\n    if data_path is not None:\n        dataset_dict = self.load_from_json(data_path)\n        super().__init__(dataset_dict)\n    elif arrow_table is not None:\n        dataset = Dataset(arrow_table)\n        super().__init__({\"train\": dataset})\n    else:\n        raise ValueError(\"Either data_path or arrow_table must be provided\")\n</code></pre>"},{"location":"reference/#luq.datasets.GenerationDataset.from_dataset","title":"<code>from_dataset(dataset)</code>  <code>classmethod</code>","text":"<p>Creates a GenerationDataset from a regular Dataset object</p> Source code in <code>luq/datasets/dataset.py</code> <pre><code>@classmethod\ndef from_dataset(cls, dataset: Dataset) -&gt; \"GenerationDataset\":\n    \"\"\"\n    Creates a GenerationDataset from a regular Dataset object\n    \"\"\"\n    return cls(arrow_table=dataset._data)\n</code></pre>"},{"location":"reference/#luq.datasets.GenerationDataset.load_from_json","title":"<code>load_from_json(data_path)</code>  <code>staticmethod</code>","text":"<p>Loads the dataset from a JSON file and converts it into a Hugging Face Dataset object.</p> Source code in <code>luq/datasets/dataset.py</code> <pre><code>@staticmethod\ndef load_from_json(data_path: str) -&gt; Dataset:\n    \"\"\"\n    Loads the dataset from a JSON file and converts it into a Hugging Face Dataset object.\n    \"\"\"\n    with open(data_path, \"r\", encoding=\"utf-8\") as f:\n        raw_data = json.load(f)\n\n    split_datasets = {}\n    for split, items in raw_data[\"data\"].items():\n        processed_items = [\n            {\n                \"question\": item[\"question\"],\n                \"samples\": item[\"samples\"],\n                \"logprobs\": item.get(\"logprobs\", []),\n                \"answer\": item[\"answer\"],\n                \"gt_answer\": item[\"gt_answer\"],\n                \"accuracy\": item.get(\"accuracy\"),\n            }\n            for item in items\n        ]\n        split_datasets[split] = Dataset.from_list(processed_items)\n    return DatasetDict(split_datasets)\n</code></pre>"},{"location":"reference/#luq.datasets.GenerationDataset.split_dataset","title":"<code>split_dataset(train_size=0.8)</code>","text":"<p>Splits the dataset into train and test sets. :param train_size: Proportion of the dataset to include in the train split. :return: Dictionary containing train and test GenerationDataset objects</p> Source code in <code>luq/datasets/dataset.py</code> <pre><code>def split_dataset(self, train_size: float = 0.8) -&gt; Dict[str, \"GenerationDataset\"]:\n    \"\"\"\n    Splits the dataset into train and test sets.\n    :param train_size: Proportion of the dataset to include in the train split.\n    :return: Dictionary containing train and test GenerationDataset objects\n    \"\"\"\n    splits = super().train_test_split(train_size=train_size)\n    return {\n        \"train\": GenerationDataset(arrow_table=splits[\"train\"]._data),\n        \"test\": GenerationDataset(arrow_table=splits[\"test\"]._data),\n    }\n</code></pre>"},{"location":"reference/#utility-functions","title":"Utility Functions","text":""},{"location":"reference/#luq.utils.entropy","title":"<code>entropy(probabilities)</code>","text":"<p>Compute entropy for a sequence of probabilities.</p> Source code in <code>luq/utils/utils.py</code> <pre><code>def entropy(probabilities: Union[List[float], torch.Tensor]) -&gt; torch.Tensor:\n    \"\"\"Compute entropy for a sequence of probabilities.\"\"\"\n    probabilities = (\n        torch.tensor(probabilities, dtype=torch.float32)\n        if isinstance(probabilities, list)\n        else probabilities\n    )\n    entropy_value = -torch.sum(probabilities * torch.log(probabilities + 1e-9))\n    return entropy_value.item()\n</code></pre>"}]}